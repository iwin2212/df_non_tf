{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd00287a30a7effb30c08c9a84f9b2fcf8ca8257de56a2e4f3f31609f559501e542",
   "display_name": "Python 3.8.8 64-bit ('demo': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0287a30a7effb30c08c9a84f9b2fcf8ca8257de56a2e4f3f31609f559501e542"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20, 2)\n    employee                                          embedding\n0        huy  [0.22873210906982422, -0.9564796686172485, -2....\n1        huy  [-0.1191978007555008, -1.648725986480713, -2.4...\n2        huy  [0.5203070640563965, -0.9194456338882446, -2.1...\n3        huy  [0.20127424597740173, -0.8754792213439941, -2....\n4        huy  [-0.11226420104503632, -0.8447368144989014, -2...\n5    dung ai  [0.9970278739929199, -1.1126073598861694, -3.1...\n6    dung ai  [0.8800203800201416, -1.1757560968399048, -3.0...\n7    dung ai  [1.2486956119537354, -1.0430350303649902, -3.2...\n8    dung ai  [1.0159077644348145, -1.186078429222107, -2.83...\n9    dung ai  [0.7063747644424438, -1.053912878036499, -2.80...\n10  dung iot  [-0.014605514705181122, -0.7461525201797485, -...\n11  dung iot  [0.022123202681541443, -0.9281516075134277, -0...\n12  dung iot  [-0.35685089230537415, -0.5286805629730225, -1...\n13  dung iot  [-0.33963507413864136, -0.3695027530193329, -0...\n14  dung iot  [-0.5359537601470947, -0.7440876960754395, -0....\n15     thang  [0.5457626581192017, -1.7796396017074585, -1.8...\n16     thang  [0.6490243673324585, -1.6345521211624146, -1.6...\n17     thang  [0.40709951519966125, -1.5133579969406128, -1....\n18     thang  [0.6650192737579346, -1.438938021659851, -1.62...\n19     thang  [0.46728816628456116, -1.5603694915771484, -1....\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from const import embedding_path\n",
    "embeddings = np.load(embedding_path, allow_pickle=True)\n",
    "df = pd.DataFrame(embeddings, columns=['employee', 'embedding'])\n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check file in snapshots exist\n",
    "import os\n",
    "from pathlib import Path\n",
    "from const import snap_path\n",
    "\n",
    "def get_img():\n",
    "   list_path = []\n",
    "   for root, dirs, files in os.walk(snap_path, topdown=False):\n",
    "      for name in files:\n",
    "         path = \"./\" + os.path.join(root, name)\n",
    "         list_path.append(path)\n",
    "   return list_path\n",
    "   \n",
    "print(get_img())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import img_path\n",
    "import os\n",
    "\n",
    "def remove_file(file_path):\n",
    "    for root, dirs, files in os.walk(file_path, topdown=False):\n",
    "        for img in files:\n",
    "            if (\".jpg\" in img):\n",
    "                print(os.path.join(root, img))\n",
    "                os.remove(os.path.join(root, img))\n",
    "remove_file(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import configration_path\n",
    "def check_configration():\n",
    "    data = open(configration_path, \"r\").read()\n",
    "    if (data.find(\"/config/tmp/camera\") != -1):\n",
    "        print(\"File {} is ready to use.\".format(configration_path[configration_path.rfind('/')+1:]))\n",
    "    else:\n",
    "        print(\"File {} is missing '/config/tmp/camera' in 'whitelist_external_dirs'\".format(configration_path[configration_path.rfind('/')+1:]))\n",
    "check_configration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from const import input_shape_size, w_min\n",
    "from utils import load_database\n",
    "from custom_deepface.deepface.commons import functions\n",
    "\n",
    "df, face_cascade = load_database()\n",
    "list_img_path = '/home/iwin/Desktop/df_non_tf/camera.jpg'\n",
    "img = cv2.imread(list_img_path)\n",
    "while(img.shape[0] > input_shape_size):\n",
    "    img = cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
    "faces = face_cascade.detectMultiScale(img,  1.3, 5)\n",
    "for (x, y, w, h) in faces:\n",
    "    if w > w_min:  # discard small detected faces\n",
    "        # -------------------------------\n",
    "        # apply deep learning for custom_face\n",
    "        base_img = img.copy()\n",
    "        img, region = functions.detect_face(\n",
    "            img=img, enforce_detection=False)\n",
    "        # --------------------------\n",
    "\n",
    "        if img.shape[0] > 0 and img.shape[1] > 0:\n",
    "            img = functions.align_face(img=img)\n",
    "        else:\n",
    "            img = base_img.copy()\n",
    "        cv2.imwrite(list_img_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import input_shape\n",
    "import numpy as np\n",
    "from view.utils.lite_predict import predict_tfmodel\n",
    "from custom_deepface.deepface.commons import distance as dst\n",
    "\n",
    "# post-processing\n",
    "img = cv2.resize(img, input_shape)\n",
    "img_pixels = np.array(img, dtype=np.float32)\n",
    "face_pixels = np.expand_dims(img_pixels, axis=0)\n",
    "face_pixels /= 255  # normalize input in [0, 1]\n",
    "\n",
    "# check preprocess_face function handled\n",
    "if face_pixels.shape[1:3] == input_shape:\n",
    "    if df.shape[0] > 0:\n",
    "        img1_representation = predict_tfmodel(face_pixels)[\n",
    "            0, :]\n",
    "\n",
    "        def findDistance(row):\n",
    "            img2_representation = row['embedding']\n",
    "            distance = dst.findCosineDistance(\n",
    "                img1_representation, img2_representation)\n",
    "            return distance\n",
    "        df['distance'] = df.apply(findDistance, axis=1)\n",
    "        df = df.sort_values(by=[\"distance\"])\n",
    "        list_candidates = df.iloc[0:3]['employee'].tolist()\n",
    "        if list_candidates.count(list_candidates[0]) >= 2:\n",
    "            candidate_label = list_candidates[0]\n",
    "        elif list_candidates.count(list_candidates[1]) >= 2:\n",
    "            candidate_label = list_candidates[1]\n",
    "        else:\n",
    "            candidate_label = 'unknown'\n",
    "print(candidate_label)"
   ]
  }
 ]
}