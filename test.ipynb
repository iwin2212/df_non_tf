{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd00287a30a7effb30c08c9a84f9b2fcf8ca8257de56a2e4f3f31609f559501e542",
   "display_name": "Python 3.8.8 64-bit ('demo': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0287a30a7effb30c08c9a84f9b2fcf8ca8257de56a2e4f3f31609f559501e542"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(51, 2)\n    employee                                          embedding\n0        huy  [1.3946319818496704, -0.2541764974594116, -1.1...\n1        huy  [-0.7068958282470703, -0.05882064998149872, -1...\n2        huy  [0.45191165804862976, 0.28204864263534546, -2....\n3        huy  [0.3449893891811371, -0.6703435182571411, -3.0...\n4        huy  [1.2440565824508667, -0.23258879780769348, -3....\n5        huy  [0.8567330837249756, 0.5315626859664917, -3.41...\n6        huy  [0.6111795902252197, 0.04968537390232086, -2.0...\n7        huy  [0.8580203056335449, -0.2516350746154785, -3.0...\n8        huy  [0.945615291595459, -0.25987350940704346, -2.8...\n9        huy  [1.0543687343597412, -0.7749121189117432, -1.6...\n10       huy  [1.2935665845870972, -0.20559996366500854, -2....\n11       huy  [0.8920835256576538, -0.46103379130363464, -1....\n12       huy  [0.33227694034576416, 0.6263231039047241, -3.2...\n13       huy  [1.2165075540542603, -0.35650166869163513, -2....\n14       huy  [1.145741581916809, 0.20029157400131226, -3.00...\n15       huy  [1.0902972221374512, -0.6571238040924072, -2.3...\n16       huy  [0.3995998203754425, 0.019509978592395782, -1....\n17       huy  [0.7054259777069092, -0.5012295246124268, -3.1...\n18       huy  [1.1506379842758179, 0.012532219290733337, -2....\n19       huy  [1.0729081630706787, -0.024479210376739502, -1...\n20  dũng IOT  [-0.11550970375537872, -0.22613336145877838, -...\n21  dũng IOT  [0.7417837381362915, -0.4351779818534851, -0.4...\n22  dũng IOT  [0.251994788646698, -0.34710702300071716, -0.8...\n23  dũng IOT  [0.7986102104187012, -0.5260436534881592, -0.2...\n24  dũng IOT  [0.33174118399620056, -0.6637802124023438, -0....\n25  dũng IOT  [0.28438350558280945, -0.952020525932312, -0.4...\n26  dũng IOT  [0.43116846680641174, -0.6801036596298218, -1....\n27  dũng IOT  [0.5736565589904785, -0.42674651741981506, -0....\n28  dũng IOT  [0.8397884368896484, -0.41629311442375183, -0....\n29  dũng IOT  [0.42734405398368835, -1.0190142393112183, -0....\n30  dũng IOT  [0.4134061634540558, -0.5748168230056763, -0.6...\n31     thắng  [1.1610583066940308, -2.2344653606414795, -2.1...\n32     thắng  [0.9127951860427856, -1.9219300746917725, -1.9...\n33     thắng  [1.3836911916732788, -1.5131314992904663, -1.2...\n34     thắng  [1.323930025100708, -1.7621594667434692, -1.01...\n35     thắng  [1.3935915231704712, -1.9295777082443237, -1.5...\n36     thắng  [0.7465192079544067, -1.3802670240402222, -1.4...\n37     thắng  [0.9114563465118408, -1.7246501445770264, -1.8...\n38     thắng  [0.9927886724472046, -1.841312289237976, -1.75...\n39     thắng  [1.174148440361023, -1.8250638246536255, -1.80...\n40     thắng  [1.261985182762146, -1.3970261812210083, -1.34...\n41     thắng  [0.7162729501724243, -0.9366656541824341, -0.2...\n42     thắng  [0.7435295581817627, -1.1466361284255981, -1.1...\n43     thắng  [1.1626683473587036, -1.8155614137649536, -1.5...\n44     thắng  [1.2631441354751587, -2.05660343170166, -1.577...\n45     thắng  [1.6978237628936768, -1.563785433769226, -1.31...\n46     thắng  [1.3714426755905151, -1.2771211862564087, -1.6...\n47     thắng  [1.3371177911758423, -1.987630009651184, -1.48...\n48     thắng  [1.6851590871810913, -1.4259485006332397, -1.4...\n49     thắng  [1.3652340173721313, -1.6206880807876587, -1.6...\n50     thắng  [0.7050081491470337, -2.167649030685425, -1.73...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from const import embedding_path\n",
    "embeddings = np.load(embedding_path, allow_pickle=True)\n",
    "df = pd.DataFrame(embeddings, columns=['employee', 'embedding'])\n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-10-366853ef5d46>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  [embeddings, np.array([label, embedding]).reshape(1, 2)], axis=0)\n",
      "1621406887.jpg\n",
      "1621406938.jpg\n",
      "1621406917.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406903.jpg\n",
      "1621406941.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406924.jpg\n",
      "1621406885.jpg\n",
      "1621406919.jpg\n",
      "1621406939.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406884.jpg\n",
      "1621406925.jpg\n",
      "1621406886.jpg\n",
      "1621406920.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406933.jpg\n",
      "1621406940.jpg\n",
      "1621406918.jpg\n",
      "1621406937.jpg\n",
      "1621406921.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406926.jpg\n",
      "1621406883.jpg\n",
      "1621406152.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406167.jpg\n",
      "1621406189.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406182.jpg\n",
      "1621406156.jpg\n",
      "1621406186.jpg\n",
      "1621406178.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406179.jpg\n",
      "1621406180.jpg\n",
      "1621406184.jpg\n",
      "1621406185.jpg\n",
      "1621406305.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406306.jpg\n",
      "1621406296.jpg\n",
      "1621406295.jpg\n",
      "1621406298.jpg\n",
      "1621406308.jpg\n",
      "1621406312.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406311.jpg\n",
      "1621406300.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406304.jpg\n",
      "1621406310.jpg\n",
      "1621406309.jpg\n",
      "1621406303.jpg\n",
      "1621406302.jpg\n",
      "1621406294.jpg\n",
      "1621406292.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406301.jpg\n",
      "1621406293.jpg\n",
      "1621406313.jpg\n",
      "1621406307.jpg\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from const import embedding_path\n",
    "from view.utils.data import add_img2db, get_face_pixels, detect_face\n",
    "import numpy as np\n",
    "from view.utils.lite_predict import predict_tfmodel\n",
    "\n",
    "\n",
    "dataset_path = \"/home/iwin/Desktop/df_non_tf/static/snap_shots\"\n",
    "for root, dirs, files in os.walk(dataset_path,  topdown=False):\n",
    "    for name in files:\n",
    "        try:\n",
    "            label = root[root.rfind('/')+1:]\n",
    "            img = detect_face(os.path.join(root, name))\n",
    "            if os.path.isfile(embedding_path):\n",
    "                embeddings = np.load(embedding_path, allow_pickle=True)\n",
    "            else:\n",
    "                embeddings = np.zeros(shape=(0, 2))\n",
    "            img_pixels = get_face_pixels(img)\n",
    "            embedding = predict_tfmodel(img_pixels)[0].tolist()\n",
    "            embedding = np.array(embedding)\n",
    "            new_embeddings = np.concatenate(\n",
    "                [embeddings, np.array([label, embedding]).reshape(1, 2)], axis=0)\n",
    "            np.save(embedding_path, new_embeddings)\n",
    "            print(name)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            continue\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from const import input_shape_size, w_min\n",
    "from utils import load_database\n",
    "from custom_deepface.deepface.commons import functions\n",
    "\n",
    "df, face_cascade = load_database()\n",
    "list_img_path = '/home/iwin/Desktop/dataset/84/A_84_0.jpg'\n",
    "img = cv2.imread(list_img_path)\n",
    "while(img.shape[0] > input_shape_size):\n",
    "    img = cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
    "faces = face_cascade.detectMultiScale(img,  1.3, 5)\n",
    "for (x, y, w, h) in faces:\n",
    "    if w > w_min:  # discard small detected faces\n",
    "        # -------------------------------\n",
    "        # apply deep learning for custom_face\n",
    "        base_img = img.copy()\n",
    "        img, region = functions.detect_face(\n",
    "            img=img, enforce_detection=False)\n",
    "        # --------------------------\n",
    "\n",
    "        if img.shape[0] > 0 and img.shape[1] > 0:\n",
    "            img = functions.align_face(img=img)\n",
    "        else:\n",
    "            img = base_img.copy()\n",
    "cv2.imshow(list_img_path, img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import input_shape, threshold\n",
    "import numpy as np\n",
    "from view.utils.lite_predict import predict_tfmodel\n",
    "from custom_deepface.deepface.commons import distance as dst\n",
    "\n",
    "# post-processing\n",
    "img = cv2.resize(img, input_shape)\n",
    "img_pixels = np.array(img, dtype=np.float32)\n",
    "face_pixels = np.expand_dims(img_pixels, axis=0)\n",
    "face_pixels /= 255  # normalize input in [0, 1]\n",
    "\n",
    "# check preprocess_face function handled\n",
    "if face_pixels.shape[1:3] == input_shape:\n",
    "    if df.shape[0] > 0:\n",
    "        img1_representation = predict_tfmodel(face_pixels)[\n",
    "            0, :]\n",
    "\n",
    "        def findDistance(row):\n",
    "            img2_representation = row['embedding']\n",
    "            distance = dst.findCosineDistance(\n",
    "                img1_representation, img2_representation)\n",
    "            return distance\n",
    "        \n",
    "        df['distance'] = df.apply(findDistance, axis=1)\n",
    "        df = df.sort_values(by=[\"distance\"])\n",
    "        \n",
    "        list_distance = df.iloc[0:3]['distance'].tolist()\n",
    "        list_candidates = df.iloc[0:3]['employee'].tolist()\n",
    "        if list_distance[0] > threshold:\n",
    "            candidate_label = 'unknown'\n",
    "        else:\n",
    "            if (list_candidates.count(list_candidates[0]) >= 2):\n",
    "                candidate_label = list_candidates[0]\n",
    "            elif (list_distance[1] < threshold and list_candidates.count(list_candidates[1]) >= 2):\n",
    "                candidate_label = list_candidates[1]\n",
    "            else:\n",
    "                candidate_label = 'unknown'\n",
    "print(candidate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     employee                                          embedding  \\\n1856       77  [0.6798121929168701, -0.2195548564195633, -1.0...   \n1861       77  [0.5230937004089355, -0.15382125973701477, -1....   \n1863       77  [0.14271309971809387, -0.16266964375972748, -1...   \n1874       77  [0.3807269334793091, -0.31144365668296814, -1....   \n1867       77  [0.4730348587036133, -0.15449300408363342, -1....   \n...       ...                                                ...   \n972        11  [-0.4137284457683563, -0.13159596920013428, -0...   \n2712       03  [-1.5341730117797852, -1.1738831996917725, 0.6...   \n2942       82  [-0.6154383420944214, -0.3314163386821747, -0....   \n2696       03  [-1.6036924123764038, -0.8304492235183716, 0.8...   \n925        02  [-1.276563286781311, -0.2367156594991684, 1.41...   \n\n     distance_metric      distance  \n1856          cosine  7.836864e-09  \n1861          cosine  1.048347e-02  \n1863          cosine  4.072545e-02  \n1874          cosine  4.263044e-02  \n1867          cosine  4.495042e-02  \n...              ...           ...  \n972           cosine  8.772479e-01  \n2712          cosine  8.774665e-01  \n2942          cosine  8.815600e-01  \n2696          cosine  9.305932e-01  \n925           cosine  9.710471e-01  \n\n[3094 rows x 4 columns]\n0.30000000000000004\n77\n0.5573630332946777\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import cv2\n",
    "from const import input_shape_size, w_min\n",
    "from utils import load_database\n",
    "from custom_deepface.deepface.commons import functions\n",
    "from const import input_shape, threshold\n",
    "import numpy as np\n",
    "from view.utils.lite_predict import predict_tfmodel\n",
    "from custom_deepface.deepface.commons import distance as dst\n",
    "import time\n",
    "\n",
    "\n",
    "prev = time.time()\n",
    "df, face_cascade = load_database()\n",
    "list_img_path = '/home/iwin/Desktop/dataset/77/A_77_0.jpg'\n",
    "img = cv2.imread(list_img_path)\n",
    "while(img.shape[0] > input_shape_size):\n",
    "    img = cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
    "faces = face_cascade.detectMultiScale(img,  1.3, 5)\n",
    "for (x, y, w, h) in faces:\n",
    "    if w > w_min:  # discard small detected faces\n",
    "        # -------------------------------\n",
    "        # apply deep learning for custom_face\n",
    "        base_img = img.copy()\n",
    "        img, region = functions.detect_face(grayscale=True,\n",
    "            img=img, enforce_detection=False)\n",
    "        # --------------------------\n",
    "\n",
    "        if img.shape[0] > 0 and img.shape[1] > 0:\n",
    "            img = functions.align_face(img=img)\n",
    "        else:\n",
    "            img = base_img.copy()\n",
    "        # cv2.imwrite(list_img_path, img)\n",
    "        # post-processing\n",
    "        img = cv2.resize(img, input_shape)\n",
    "        img_pixels = np.array(img, dtype=np.float32)\n",
    "        face_pixels = np.expand_dims(img_pixels, axis=0)\n",
    "        face_pixels /= 255  # normalize input in [0, 1]\n",
    "\n",
    "        # check preprocess_face function handled\n",
    "        if face_pixels.shape[1:3] == input_shape:\n",
    "            if df.shape[0] > 0:\n",
    "                img1_representation = predict_tfmodel(face_pixels)[\n",
    "                    0, :]\n",
    "\n",
    "                def findDistance(row):\n",
    "                    img2_representation = row['embedding']\n",
    "                    distance = dst.findCosineDistance(\n",
    "                        img1_representation, img2_representation)\n",
    "                    return distance\n",
    "                \n",
    "                df['distance'] = df.apply(findDistance, axis=1)\n",
    "                df = df.sort_values(by=[\"distance\"])\n",
    "                print(df)\n",
    "                print(threshold)\n",
    "                list_distance = df.iloc[0:3]['distance'].tolist()\n",
    "                list_candidates = df.iloc[0:3]['employee'].tolist()\n",
    "                if list_distance[0] > threshold:\n",
    "                    candidate_label = 'unknown'\n",
    "                else:\n",
    "                    if (list_candidates.count(list_candidates[0]) >= 2):\n",
    "                        candidate_label = list_candidates[0]\n",
    "                    elif (list_distance[1] < threshold and list_candidates.count(list_candidates[1]) >= 2):\n",
    "                        candidate_label = list_candidates[1]\n",
    "                    else:\n",
    "                        candidate_label = 'unknown'\n",
    "        print(candidate_label)\n",
    "print(time.time() - prev)\n",
    "# cv2.imshow(\"img\",img)\n",
    "cv2.waitKey()"
   ]
  }
 ]
}