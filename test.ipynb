{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd00287a30a7effb30c08c9a84f9b2fcf8ca8257de56a2e4f3f31609f559501e542",
   "display_name": "Python 3.8.8 64-bit ('demo': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0287a30a7effb30c08c9a84f9b2fcf8ca8257de56a2e4f3f31609f559501e542"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20, 2)\n    employee                                          embedding\n0        huy  [0.22873210906982422, -0.9564796686172485, -2....\n1        huy  [-0.1191978007555008, -1.648725986480713, -2.4...\n2        huy  [0.5203070640563965, -0.9194456338882446, -2.1...\n3        huy  [0.20127424597740173, -0.8754792213439941, -2....\n4        huy  [-0.11226420104503632, -0.8447368144989014, -2...\n5    dung ai  [0.9970278739929199, -1.1126073598861694, -3.1...\n6    dung ai  [0.8800203800201416, -1.1757560968399048, -3.0...\n7    dung ai  [1.2486956119537354, -1.0430350303649902, -3.2...\n8    dung ai  [1.0159077644348145, -1.186078429222107, -2.83...\n9    dung ai  [0.7063747644424438, -1.053912878036499, -2.80...\n10  dung iot  [-0.014605514705181122, -0.7461525201797485, -...\n11  dung iot  [0.022123202681541443, -0.9281516075134277, -0...\n12  dung iot  [-0.35685089230537415, -0.5286805629730225, -1...\n13  dung iot  [-0.33963507413864136, -0.3695027530193329, -0...\n14  dung iot  [-0.5359537601470947, -0.7440876960754395, -0....\n15     thang  [0.5457626581192017, -1.7796396017074585, -1.8...\n16     thang  [0.6490243673324585, -1.6345521211624146, -1.6...\n17     thang  [0.40709951519966125, -1.5133579969406128, -1....\n18     thang  [0.6650192737579346, -1.438938021659851, -1.62...\n19     thang  [0.46728816628456116, -1.5603694915771484, -1....\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from const import embedding_path\n",
    "embeddings = np.load(embedding_path, allow_pickle=True)\n",
    "df = pd.DataFrame(embeddings, columns=['employee', 'embedding'])\n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-10-366853ef5d46>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  [embeddings, np.array([label, embedding]).reshape(1, 2)], axis=0)\n",
      "1621406887.jpg\n",
      "1621406938.jpg\n",
      "1621406917.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406903.jpg\n",
      "1621406941.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406924.jpg\n",
      "1621406885.jpg\n",
      "1621406919.jpg\n",
      "1621406939.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406884.jpg\n",
      "1621406925.jpg\n",
      "1621406886.jpg\n",
      "1621406920.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406933.jpg\n",
      "1621406940.jpg\n",
      "1621406918.jpg\n",
      "1621406937.jpg\n",
      "1621406921.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406926.jpg\n",
      "1621406883.jpg\n",
      "1621406152.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406167.jpg\n",
      "1621406189.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406182.jpg\n",
      "1621406156.jpg\n",
      "1621406186.jpg\n",
      "1621406178.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406179.jpg\n",
      "1621406180.jpg\n",
      "1621406184.jpg\n",
      "1621406185.jpg\n",
      "1621406305.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406306.jpg\n",
      "1621406296.jpg\n",
      "1621406295.jpg\n",
      "1621406298.jpg\n",
      "1621406308.jpg\n",
      "1621406312.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406311.jpg\n",
      "1621406300.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406304.jpg\n",
      "1621406310.jpg\n",
      "1621406309.jpg\n",
      "1621406303.jpg\n",
      "1621406302.jpg\n",
      "1621406294.jpg\n",
      "1621406292.jpg\n",
      "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "1621406301.jpg\n",
      "1621406293.jpg\n",
      "1621406313.jpg\n",
      "1621406307.jpg\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from const import embedding_path\n",
    "from view.utils.data import add_img2db, get_face_pixels, detect_face\n",
    "import numpy as np\n",
    "from view.utils.lite_predict import predict_tfmodel\n",
    "\n",
    "\n",
    "dataset_path = \"/home/iwin/Desktop/df_non_tf/static/snap_shots\"\n",
    "for root, dirs, files in os.walk(dataset_path,  topdown=False):\n",
    "    for name in files:\n",
    "        try:\n",
    "            label = root[root.rfind('/')+1:]\n",
    "            img = detect_face(os.path.join(root, name))\n",
    "            if os.path.isfile(embedding_path):\n",
    "                embeddings = np.load(embedding_path, allow_pickle=True)\n",
    "            else:\n",
    "                embeddings = np.zeros(shape=(0, 2))\n",
    "            img_pixels = get_face_pixels(img)\n",
    "            embedding = predict_tfmodel(img_pixels)[0].tolist()\n",
    "            embedding = np.array(embedding)\n",
    "            new_embeddings = np.concatenate(\n",
    "                [embeddings, np.array([label, embedding]).reshape(1, 2)], axis=0)\n",
    "            np.save(embedding_path, new_embeddings)\n",
    "            print(name)\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            continue\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from const import input_shape_size, w_min\n",
    "from utils import load_database\n",
    "from custom_deepface.deepface.commons import functions\n",
    "\n",
    "df, face_cascade = load_database()\n",
    "list_img_path = '/home/iwin/Desktop/dataset/84/A_84_0.jpg'\n",
    "img = cv2.imread(list_img_path)\n",
    "while(img.shape[0] > input_shape_size):\n",
    "    img = cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
    "faces = face_cascade.detectMultiScale(img,  1.3, 5)\n",
    "for (x, y, w, h) in faces:\n",
    "    if w > w_min:  # discard small detected faces\n",
    "        # -------------------------------\n",
    "        # apply deep learning for custom_face\n",
    "        base_img = img.copy()\n",
    "        img, region = functions.detect_face(\n",
    "            img=img, enforce_detection=False)\n",
    "        # --------------------------\n",
    "\n",
    "        if img.shape[0] > 0 and img.shape[1] > 0:\n",
    "            img = functions.align_face(img=img)\n",
    "        else:\n",
    "            img = base_img.copy()\n",
    "cv2.imshow(list_img_path, img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import input_shape, threshold\n",
    "import numpy as np\n",
    "from view.utils.lite_predict import predict_tfmodel\n",
    "from custom_deepface.deepface.commons import distance as dst\n",
    "\n",
    "# post-processing\n",
    "img = cv2.resize(img, input_shape)\n",
    "img_pixels = np.array(img, dtype=np.float32)\n",
    "face_pixels = np.expand_dims(img_pixels, axis=0)\n",
    "face_pixels /= 255  # normalize input in [0, 1]\n",
    "\n",
    "# check preprocess_face function handled\n",
    "if face_pixels.shape[1:3] == input_shape:\n",
    "    if df.shape[0] > 0:\n",
    "        img1_representation = predict_tfmodel(face_pixels)[\n",
    "            0, :]\n",
    "\n",
    "        def findDistance(row):\n",
    "            img2_representation = row['embedding']\n",
    "            distance = dst.findCosineDistance(\n",
    "                img1_representation, img2_representation)\n",
    "            return distance\n",
    "        \n",
    "        df['distance'] = df.apply(findDistance, axis=1)\n",
    "        df = df.sort_values(by=[\"distance\"])\n",
    "        \n",
    "        list_distance = df.iloc[0:3]['distance'].tolist()\n",
    "        list_candidates = df.iloc[0:3]['employee'].tolist()\n",
    "        if list_distance[0] > threshold:\n",
    "            candidate_label = 'unknown'\n",
    "        else:\n",
    "            if (list_candidates.count(list_candidates[0]) >= 2):\n",
    "                candidate_label = list_candidates[0]\n",
    "            elif (list_distance[1] < threshold and list_candidates.count(list_candidates[1]) >= 2):\n",
    "                candidate_label = list_candidates[1]\n",
    "            else:\n",
    "                candidate_label = 'unknown'\n",
    "print(candidate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     employee                                          embedding  \\\n1856       77  [0.6798121929168701, -0.2195548564195633, -1.0...   \n1861       77  [0.5230937004089355, -0.15382125973701477, -1....   \n1863       77  [0.14271309971809387, -0.16266964375972748, -1...   \n1874       77  [0.3807269334793091, -0.31144365668296814, -1....   \n1867       77  [0.4730348587036133, -0.15449300408363342, -1....   \n...       ...                                                ...   \n972        11  [-0.4137284457683563, -0.13159596920013428, -0...   \n2712       03  [-1.5341730117797852, -1.1738831996917725, 0.6...   \n2942       82  [-0.6154383420944214, -0.3314163386821747, -0....   \n2696       03  [-1.6036924123764038, -0.8304492235183716, 0.8...   \n925        02  [-1.276563286781311, -0.2367156594991684, 1.41...   \n\n     distance_metric      distance  \n1856          cosine  7.836864e-09  \n1861          cosine  1.048347e-02  \n1863          cosine  4.072545e-02  \n1874          cosine  4.263044e-02  \n1867          cosine  4.495042e-02  \n...              ...           ...  \n972           cosine  8.772479e-01  \n2712          cosine  8.774665e-01  \n2942          cosine  8.815600e-01  \n2696          cosine  9.305932e-01  \n925           cosine  9.710471e-01  \n\n[3094 rows x 4 columns]\n0.30000000000000004\n77\n0.5573630332946777\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import cv2\n",
    "from const import input_shape_size, w_min\n",
    "from utils import load_database\n",
    "from custom_deepface.deepface.commons import functions\n",
    "from const import input_shape, threshold\n",
    "import numpy as np\n",
    "from view.utils.lite_predict import predict_tfmodel\n",
    "from custom_deepface.deepface.commons import distance as dst\n",
    "import time\n",
    "\n",
    "\n",
    "prev = time.time()\n",
    "df, face_cascade = load_database()\n",
    "list_img_path = '/home/iwin/Desktop/dataset/77/A_77_0.jpg'\n",
    "img = cv2.imread(list_img_path)\n",
    "while(img.shape[0] > input_shape_size):\n",
    "    img = cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))\n",
    "faces = face_cascade.detectMultiScale(img,  1.3, 5)\n",
    "for (x, y, w, h) in faces:\n",
    "    if w > w_min:  # discard small detected faces\n",
    "        # -------------------------------\n",
    "        # apply deep learning for custom_face\n",
    "        base_img = img.copy()\n",
    "        img, region = functions.detect_face(grayscale=True,\n",
    "            img=img, enforce_detection=False)\n",
    "        # --------------------------\n",
    "\n",
    "        if img.shape[0] > 0 and img.shape[1] > 0:\n",
    "            img = functions.align_face(img=img)\n",
    "        else:\n",
    "            img = base_img.copy()\n",
    "        # cv2.imwrite(list_img_path, img)\n",
    "        # post-processing\n",
    "        img = cv2.resize(img, input_shape)\n",
    "        img_pixels = np.array(img, dtype=np.float32)\n",
    "        face_pixels = np.expand_dims(img_pixels, axis=0)\n",
    "        face_pixels /= 255  # normalize input in [0, 1]\n",
    "\n",
    "        # check preprocess_face function handled\n",
    "        if face_pixels.shape[1:3] == input_shape:\n",
    "            if df.shape[0] > 0:\n",
    "                img1_representation = predict_tfmodel(face_pixels)[\n",
    "                    0, :]\n",
    "\n",
    "                def findDistance(row):\n",
    "                    img2_representation = row['embedding']\n",
    "                    distance = dst.findCosineDistance(\n",
    "                        img1_representation, img2_representation)\n",
    "                    return distance\n",
    "                \n",
    "                df['distance'] = df.apply(findDistance, axis=1)\n",
    "                df = df.sort_values(by=[\"distance\"])\n",
    "                print(df)\n",
    "                print(threshold)\n",
    "                list_distance = df.iloc[0:3]['distance'].tolist()\n",
    "                list_candidates = df.iloc[0:3]['employee'].tolist()\n",
    "                if list_distance[0] > threshold:\n",
    "                    candidate_label = 'unknown'\n",
    "                else:\n",
    "                    if (list_candidates.count(list_candidates[0]) >= 2):\n",
    "                        candidate_label = list_candidates[0]\n",
    "                    elif (list_distance[1] < threshold and list_candidates.count(list_candidates[1]) >= 2):\n",
    "                        candidate_label = list_candidates[1]\n",
    "                    else:\n",
    "                        candidate_label = 'unknown'\n",
    "        print(candidate_label)\n",
    "print(time.time() - prev)\n",
    "# cv2.imshow(\"img\",img)\n",
    "cv2.waitKey()"
   ]
  }
 ]
}